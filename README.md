# Bike-Rental-Prediction-Regression
## <b>PROBLEM CONTEXT
<b>

-  As bike-sharing becomes an increasingly important mode of urban transportation, understanding and forecasting bike rental demand is crucial for efficient resource allocation, maintenance planning, and user satisfaction. Using the provided dataset (both daily and hourly records), we aim to build machine learning models that accurately estimate rental counts to support better decision-making for smart city mobility systems.
-  The goal of this project is to predict the number of bikes rented in a bike-sharing system based on historical rental data and contextual features such as weather conditions, time of day, season, and holidays.


### <b>TASK 1
#### <b>PREPARE A COMPLETE DATA ANALYSIS REPORT ON THE GIVEN DATA.
### <b>TASK 2
#### <b>PREDICTION OF DAILY BIKE RENTAL COUNT BASED ON THE ENVIRONMENT AND SEASONAL SETTINGS.


### <b>TYPE OF MACHINE LEARNING PROBLEM.
- <b>It is a Regression problem, where given the above set of features, we aim to build machine learning models that accurately estimate rental counts to support better decision-making for smart city mobility systems.<br>
### <b>LIST OF ALGORITHMS USES FOR Regression
<b>
    
- Linear Regression
- Support Vector Regressor
- KNeighborsRegressor
- DecisionTreeRegressor
- RandomForestRegressor
- GradientBoostingRegressor
- XGBRegressor


## <b>DATASET OVERVIEW
<b>Bike sharing systems are a new version of traditional bike rentals where the whole process from membership, rental and return back has been automated. Through these systems, users are easily able to rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns the bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of the important events in the city could be detected via monitoring these data.</b>

#### <b>Feature	Description
- <b>Age</b><br>Age of the person

- <b>instant:</b><br> record index
- <b>dteday :</b><br> date
- <b>season :</b><br> season (1:winter, 2:spring, 3:summer, 4:fall)
- <b>yr :</b><br> year (0: 2011, 1:2012)
- <b>mnth :</b><br> month ( 1 to 12)
- <b>hr :</b><br> hour (0 to 23)
- <b>holiday :</b><br> weather day is holiday or not (extracted from [Web Link])
- <b>weekday :</b><br> day of the week

- <b>workingday :</b><br> if neither weekend nor holiday, it is 1; otherwise 0.
- <b>weathersit :</b><br>
    - 1: Clear, Few clouds, Partly cloudy, Partly cloudy
    - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
    - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
    - 4: Heavy Rain + Ice Pellets + Thunderstorm + Mist, Snow + Fog
- <b>temp :</b><br> Normalized temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-8, t_max=+39 (only in hourly scale)
- <b>atemp:</b><br> Normalized feeling temperature in Celsius. The values are derived via (t-t_min)/(t_max-t_min), t_min=-16, t_max=+50 (only in hourly scale)
- <b>hum:</b><br> Normalized humidity. The values are divided to 100 (max)
- <b>windspeed:</b><br> Normalized wind speed. The values are divided to 67 (max)
- <b>casual:</b><br> count of casual users
- <b>registered:</b><br> count of registered users
- <b>cnt:</b><br> count of total rental bikes including both casual and registered



### <b>RESULT SUMMARY BEFORE TUNNING
<b>
    
- Linear Regression:
The R-squared value is low for both training (0.3172) and testing (0.3107). This indicates that the model is struggling to explain the variance in the data. The performance is poor for both training and testing datasets, suggesting the model is not able to capture the underlying patterns in the data.

- Decision Tree Regressor:
The model has a high R-squared value on the training data (0.9754), but the test R-squared is very low (0.0444), suggesting severe overfitting. It has learned the training data very well but fails to generalize to new data. This indicates that the model is memorizing the training data rather than learning meaningful patterns.

- Random Forest Regressor:
This model performs moderately well on the training set (R² = 0.8740) and slightly better on the test set (R² = 0.4133). While the performance is better than some other models, there is still room for improvement in generalization. The moderate drop in performance suggests that the model is not overfitting as much as the Decision Tree, but it could still be optimized.

- K-Nearest Neighbors (KNN) Regressor Model:
The KNN model shows relatively low R-squared values (0.5297 on training and 0.4107 on testing), suggesting underfitting. It doesn’t capture the variance in the data effectively, especially when compared to more complex models like Random Forest or Decision Tree.

- XGBoost:
The model performs poorly on both training (R² = 0.6357) and test data (R² = -0.0992). The negative test R² indicates that the model is performing worse than a simple mean prediction for the test data. This suggests that XGBoost might be overfitting or struggling with the data in its current form, requiring tuning or feature engineering.

- Gradient Boosting Regressor:
Similar to XGBoost, the Gradient Boosting model shows a moderate performance on the training set (R² = 0.4464) but performs poorly on the test set (R² = 0.0744). The very low test R² indicates that the model struggles to generalize and could benefit from hyperparameter tuning or additional feature selection.

- Support Vector Regressor (SVR):
SVR shows very low performance with an R-squared value of 0.2223 on the training data and 0.0725 on the test data. This indicates underfitting, and the model is not able to explain the variance in the data effectively, likely due to its inability to capture complex relationships within the dataset.


| Model                               | Train R² Score | Test R² Score |
| ----------------------------------- | -------------- | ------------- |
| Linear Regression                   | 0.3172         | 0.3107        |
| Decision Tree Regressor             | 0.9754         | 0.0444        |
| Random Forest Regressor             | 0.8740         | 0.4133        |
| K-Nearest Neighbors (KNN) Regressor | 0.5297         | 0.4107        |
| XGBoost                             | 0.6357         | -0.0992       |
| Gradient Boosting Regressor         | 0.4464         | 0.0744        |
| Support Vector Regressor            | 0.2223         | 0.0725        |



## <B>COMPARISION OF MODELS BEFORE AND AFTER HYPERTUNNING
| **Model**                          | **Train R² (Before)** | **Test R² (Before)** | **RMSE (After)** | **MAE (After)** | **R² (After)** | **Interpretation**                                                                                             |
| ---------------------------------- | --------------------- | -------------------- | ---------------- | --------------- | -------------- | -------------------------------------------------------------------------------------------------------------- |
| **Linear Regression**              | 0.3172                | 0.3107               | 147.73           | 112.16          | 0.31           | Poor performance both before and after tuning. The model struggles to explain the variance in the data.        |
| **Decision Tree Regressor**        | 0.9754                | 0.0444               | 175.49           | 118.59          | 0.03           | Overfitting observed. High training R² but very poor test R². Hyperparameter tuning does not improve much.     |
| **Random Forest Regressor**        | 0.8740                | 0.4133               | 131.18           | 95.65           | 0.46           | After tuning, it performs reasonably well but still shows signs of overfitting. Best performance after tuning. |
| **K-Nearest Neighbors (KNN)**      | 0.5297                | 0.4107               | 137.18           | 97.74           | 0.41           | No major improvements with tuning. Performs below other models, indicating its limitations for this dataset.   |
| **XGBoost**                        | 0.6357                | -0.0992              | 133.55           | 98.35           | 0.44           | Significant improvement post-tuning, but still overfits and underperforms compared to Random Forest.           |
| **Gradient Boosting Regressor**    | 0.4464                | 0.0744               | 134.66           | 99.11           | 0.43           | Tuning leads to a slight performance boost, but it still lags behind other models in explaining the variance.  |
| **Support Vector Regressor (SVR)** | 0.2223                | 0.0725               | 156.13           | 109.01          | 0.23           | Remains weak even after tuning. Poor R² and high RMSE/MAE indicate poor predictive power.                      |



### <B>CONCLUSION
<B>
    
- Random Forest is the most effective model, with the highest test R² and reasonable RMSE after hyperparameter tuning.
- Decision Tree and XGBoost exhibit overfitting, as shown by the large difference between their training and testing performance.
- K-Nearest Neighbors (KNN) remains weak and does not improve much with tuning.
- Linear Regression and SVR both perform poorly both before and after tuning.


## <B>DAILY BIKE RENTAL FACTORS HELP ACHIEVE BUSINESS GOALS
| **Business Goal**                   | **Related Feature(s)**                        | **How the Data Helps Achieve the Goal**                                                                                                     |
| ----------------------------------- | --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------- |
| Maximize Rentals and Revenue        | season, mnth, weekday, hr, temp               | Identifies peak seasons, days, and hours for demand — helps in planning promotions, pricing, and inventory.                                 |
| Forecast Demand Accurately          | temp, atemp, hum, windspeed, weathersit       | Environmental features improve accuracy of predictions — useful for resource forecasting and staff allocation.                              |
| Improve Resource Allocation         | hr, workingday, holiday, weekday, cnt         | Pinpoints times of day or week where more or fewer bikes or staff are needed — avoids over/under-stocking.                                  |
| Target Promotions Effectively       | casual, registered, holiday, season           | Helps differentiate marketing strategies for new (casual) vs repeat (registered) users, and optimize campaigns around holidays and seasons. |
| Reduce Operational Costs            | weathersit, hum, windspeed, low cnt intervals | Detects periods of low demand or bad weather to reduce costs (e.g., limit logistics, shift maintenance).                                    |
| Expand or Shift Fleet Strategically | cnt, registered, location (if available)      | Predicts growth areas and time slots for demand — enables smart decisions on where and when to add or relocate bikes.                       |
| Understand User Behavior            | casual, registered, hr, weekday, workingday   | Shows how user types differ in patterns — helps design better user experiences (e.g., app recommendations, loyalty offers, etc.).           |


| **Factor**       | **Business Impact**                                                            |
| ---------------- | ------------------------------------------------------------------------------ |
| temp / atemp | More rentals on warmer days, increase fleet on such days.                 |
| season         | Summer/winter trends reveal seasonal marketing strategies.                 |
| workingday     | Rentals differ between workdays and weekends, balance supply accordingly. |
| humidity       | High humidity leads to fewer rides, avoid oversupply.                         |
| windspeed      | High wind = low demand,reduce active bikes in poor weather.              |
| holiday        | Holidays spike demand for leisure trips, promote tourist-friendly routes. |


